{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49a1d580",
   "metadata": {},
   "source": [
    "# PROJET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aeb0881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.10.8\n",
      "tiktoken version: 0.12.0\n",
      "torch version: 2.11.0.dev20260131+cu128\n",
      "tqdm version: 4.67.2\n",
      "tensorflow version: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\n",
    "    \"matplotlib\",  # Plotting library\n",
    "    \"tiktoken\",    # Tokenizer\n",
    "    \"torch\",       # Deep learning library\n",
    "    \"tqdm\",        # Progress bar\n",
    "    \"tensorflow\",  # For OpenAI's pretrained weights\n",
    "]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f75ce9c",
   "metadata": {},
   "source": [
    "## 1° Création et préparation du dataset\n",
    "\n",
    "### 1.1° Création du dataset\n",
    "\n",
    "J'ai choisi une IA qui va aider pour la cuisine\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4ac8b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "def create_shuffled_dataset(output_path,files):\n",
    "\n",
    "    all_data = []\n",
    "\n",
    "    # Charger tous les fichiers\n",
    "    for file_path in files:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "            all_data.extend(data)\n",
    "\n",
    "    # Mélanger aléatoirement\n",
    "    random.shuffle(all_data)\n",
    "\n",
    "    # Sauvegarder dans dataset_final.json\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(all_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"Dataset final créé avec {len(all_data)} exemples → {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "323eb711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset final créé avec 1371 exemples → datasets/dataset_final_with_response_initial.json\n"
     ]
    }
   ],
   "source": [
    "output_path=\"datasets/dataset_final_with_response_initial.json\"\n",
    "\n",
    "files = [\n",
    "        \"datasets/conversion_ingredients_litre.json\",\n",
    "        \"datasets/conversion_ingredients_kg.json\",\n",
    "        \"datasets/ingredients_recettes_desserts.json\",\n",
    "        \"datasets/ingredients_recettes_plats.json\",\n",
    "        \"datasets/cuisson_recette.json\",\n",
    "        \"datasets/recette_viande_poisson.json\",\n",
    "    ]\n",
    "\n",
    "\n",
    "create_shuffled_dataset(output_path,files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd68b3aa",
   "metadata": {},
   "source": [
    "### 1.2° Préparation du dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41feba81",
   "metadata": {},
   "source": [
    "On doit retirer la partie réponse pour l'entrainememt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fc9e9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def remove_model_response(input_path: str, output_path: str = None) -> str:\n",
    "\n",
    "    input_file = Path(input_path)\n",
    "\n",
    "    if output_path is None:\n",
    "        output_file = input_file.with_name(input_file.stem + \"_train.json\")\n",
    "    else:\n",
    "        output_file = Path(output_path)\n",
    "\n",
    "    # Lire le JSON\n",
    "    with input_file.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Vérification minimale\n",
    "    if not isinstance(data, list):\n",
    "        raise ValueError(\"Le JSON doit être une liste d'objets (list).\")\n",
    "\n",
    "    cleaned = []\n",
    "    for i, entry in enumerate(data):\n",
    "        if not isinstance(entry, dict):\n",
    "            raise ValueError(f\"Entrée #{i} invalide : attendu dict, obtenu {type(entry)}\")\n",
    "\n",
    "        # Copier et enlever model_response si présent\n",
    "        new_entry = dict(entry)\n",
    "        new_entry.pop(\"model_response\", None)\n",
    "\n",
    "        # (Optionnel) vérifier que les clés nécessaires existent\n",
    "        for key in (\"instruction\", \"input\", \"output\"):\n",
    "            if key not in new_entry:\n",
    "                raise ValueError(f\"Entrée #{i} : clé manquante '{key}'\")\n",
    "\n",
    "        cleaned.append(new_entry)\n",
    "\n",
    "    # Sauvegarde\n",
    "    with output_file.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(cleaned, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    return str(output_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af14f5bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'datasets\\\\dataset_final.json'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file = \"datasets/dataset_final_with_response_initial.json\"\n",
    "output_path =\"datasets/dataset_final.json\"\n",
    "remove_model_response(input_file,output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb2128a",
   "metadata": {},
   "source": [
    "On charge maintenant le dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc99be66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    else:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text_data = file.read()\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c01f509c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1371\n"
     ]
    }
   ],
   "source": [
    "file_path = \"datasets/dataset_final.json\"\n",
    "url = \"\"\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b83938",
   "metadata": {},
   "source": [
    "On met sous format de pour les batchs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbaed3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Voici une instruction qui décrit une tâche. \"\n",
    "        f\"Rédige une réponse qui complète correctement la demande.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6ca33a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voici une instruction qui décrit une tâche. Rédige une réponse qui complète correctement la demande.\n",
      "\n",
      "### Instruction:\n",
      "Convertis 12 cl en ml.\n"
     ]
    }
   ],
   "source": [
    "print(format_input(data[90]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15694de3",
   "metadata": {},
   "source": [
    "Séparation du dataset en ensemble d'entrainement de test et de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b7569ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_portion = int(len(data) * 0.85)  # 85% for training\n",
    "test_portion = int(len(data) * 0.1)    # 10% for testing\n",
    "val_portion = len(data) - train_portion - test_portion  # Remaining 5% for validation\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73675599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 1165\n",
      "Validation set length: 69\n",
      "Test set length: 137\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa56616",
   "metadata": {},
   "source": [
    "### 1.3° Organizing data into training batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bac868e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bd76f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b61028a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_1(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs\n",
    "    inputs_lst = []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        # this always adds at least 1 additional padding tokens\n",
    "        padded = new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        # We remove this extra padded token again here\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        inputs_lst.append(inputs)\n",
    "\n",
    "    # Convert list of inputs to tensor and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    return inputs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "541851c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_2(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # Convert list of inputs to tensor and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fc3e0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs and targets\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "\n",
    "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "\n",
    "        # New: Optionally truncate to maximum sequence length\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # Convert list of inputs and targets to tensors and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a40e46",
   "metadata": {},
   "source": [
    "### 1.4° Creating data loaders for an instruction dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e73407",
   "metadata": {},
   "source": [
    "- In this section, we use the `InstructionDataset` class and `custom_collate_fn` function to instantiate the training, validation, and test data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bbe20ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# If you have a Mac with Apple Silicon chip, you can uncomment the next lines of code\n",
    "# to train the model on the Mac's GPU cores. However, as of this writing, this results in\n",
    "# larger numerical deviations from the results shown in this lab, because Apple Silicon\n",
    "# support in PyTorch is still experimental\n",
    "\n",
    "# if torch.backends.mps.is_available():\n",
    "#     device = torch.device(\"mps\")\n",
    "\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "695f50b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "customized_collate_fn = partial(custom_collate_fn, device=device, allowed_max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bc47bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffda16fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 94]) torch.Size([8, 94])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 84]) torch.Size([8, 84])\n",
      "torch.Size([8, 85]) torch.Size([8, 85])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 96]) torch.Size([8, 96])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 84]) torch.Size([8, 84])\n",
      "torch.Size([8, 102]) torch.Size([8, 102])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 85]) torch.Size([8, 85])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 90]) torch.Size([8, 90])\n",
      "torch.Size([8, 96]) torch.Size([8, 96])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 95]) torch.Size([8, 95])\n",
      "torch.Size([8, 86]) torch.Size([8, 86])\n",
      "torch.Size([8, 101]) torch.Size([8, 101])\n",
      "torch.Size([8, 86]) torch.Size([8, 86])\n",
      "torch.Size([8, 101]) torch.Size([8, 101])\n",
      "torch.Size([8, 93]) torch.Size([8, 93])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 84]) torch.Size([8, 84])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 85]) torch.Size([8, 85])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 90]) torch.Size([8, 90])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 92]) torch.Size([8, 92])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 85]) torch.Size([8, 85])\n",
      "torch.Size([8, 95]) torch.Size([8, 95])\n",
      "torch.Size([8, 85]) torch.Size([8, 85])\n",
      "torch.Size([8, 84]) torch.Size([8, 84])\n",
      "torch.Size([8, 90]) torch.Size([8, 90])\n",
      "torch.Size([8, 84]) torch.Size([8, 84])\n",
      "torch.Size([8, 94]) torch.Size([8, 94])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 84]) torch.Size([8, 84])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 109]) torch.Size([8, 109])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 94]) torch.Size([8, 94])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 86]) torch.Size([8, 86])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 85]) torch.Size([8, 85])\n",
      "torch.Size([8, 86]) torch.Size([8, 86])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 93]) torch.Size([8, 93])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 98]) torch.Size([8, 98])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 94]) torch.Size([8, 94])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 84]) torch.Size([8, 84])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 86]) torch.Size([8, 86])\n",
      "torch.Size([8, 86]) torch.Size([8, 86])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 99]) torch.Size([8, 99])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 85]) torch.Size([8, 85])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 85]) torch.Size([8, 85])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 84]) torch.Size([8, 84])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 92]) torch.Size([8, 92])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 85]) torch.Size([8, 85])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 86]) torch.Size([8, 86])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 86]) torch.Size([8, 86])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 85]) torch.Size([8, 85])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 97]) torch.Size([8, 97])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 85]) torch.Size([8, 85])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 86]) torch.Size([8, 86])\n",
      "torch.Size([8, 84]) torch.Size([8, 84])\n",
      "torch.Size([8, 85]) torch.Size([8, 85])\n",
      "torch.Size([8, 99]) torch.Size([8, 99])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 95]) torch.Size([8, 95])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 84]) torch.Size([8, 84])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 94]) torch.Size([8, 94])\n",
      "torch.Size([8, 90]) torch.Size([8, 90])\n",
      "torch.Size([8, 84]) torch.Size([8, 84])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 86]) torch.Size([8, 86])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 90]) torch.Size([8, 90])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "145\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)\n",
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5077401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([42144, 44070, 17809, 12064, 45567, 39073, 22213, 17809,   256, 22940,\n",
      "         2395,    13, 47957,    67, 10045, 17809, 40560,    79,  2591, 45567,\n",
      "         2299, 14064,   660,  3376,   972,  8591,  3512,    68,    13,   198,\n",
      "          198, 21017, 46486,    25,   198,  3103,  3346,  1315, 25962,   551,\n",
      "          406,    13,   198,   198, 21017, 18261,    25,   198,  1314, 25962,\n",
      "          796,   657,    13, 25150,   406, 50256, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(inputs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87d59f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([44070, 17809, 12064, 45567, 39073, 22213, 17809,   256, 22940,  2395,\n",
      "           13, 47957,    67, 10045, 17809, 40560,    79,  2591, 45567,  2299,\n",
      "        14064,   660,  3376,   972,  8591,  3512,    68,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  3103,  3346,  1315, 25962,   551,   406,\n",
      "           13,   198,   198, 21017, 18261,    25,   198,  1314, 25962,   796,\n",
      "          657,    13, 25150,   406, 50256,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(targets[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c0bd6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "customized_collate_fn = partial(custom_collate_fn, device=device, allowed_max_length=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ed6600",
   "metadata": {},
   "source": [
    "## 2° Finetune le model\n",
    "\n",
    "### 2.1° Loading a pretrained LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "250270c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\355M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2\\355M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2\\355M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\355M\\vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from previous_labs import GPTModel, load_weights_into_gpt\n",
    "\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c93d67",
   "metadata": {},
   "source": [
    "### 2.2°Finetuning the LLM on instruction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1696fe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_labs import (\n",
    "    calc_loss_loader,\n",
    "    train_model_simple\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8842400a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 4.8678998947143555\n",
      "Validation loss: 4.8922295570373535\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d030960b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 3.386, Val loss 3.354\n",
      "Ep 1 (Step 000005): Train loss 1.163, Val loss 1.000\n",
      "Ep 1 (Step 000010): Train loss 0.688, Val loss 0.654\n",
      "Ep 1 (Step 000015): Train loss 0.548, Val loss 0.545\n",
      "Ep 1 (Step 000020): Train loss 0.574, Val loss 0.485\n",
      "Ep 1 (Step 000025): Train loss 0.448, Val loss 0.450\n",
      "Ep 1 (Step 000030): Train loss 0.464, Val loss 0.428\n",
      "Ep 1 (Step 000035): Train loss 0.422, Val loss 0.404\n",
      "Ep 1 (Step 000040): Train loss 0.411, Val loss 0.394\n",
      "Ep 1 (Step 000045): Train loss 0.409, Val loss 0.376\n",
      "Ep 1 (Step 000050): Train loss 0.298, Val loss 0.360\n",
      "Ep 1 (Step 000055): Train loss 0.347, Val loss 0.350\n",
      "Ep 1 (Step 000060): Train loss 0.322, Val loss 0.343\n",
      "Ep 1 (Step 000065): Train loss 0.333, Val loss 0.338\n",
      "Ep 1 (Step 000070): Train loss 0.308, Val loss 0.335\n",
      "Ep 1 (Step 000075): Train loss 0.276, Val loss 0.332\n",
      "Ep 1 (Step 000080): Train loss 0.281, Val loss 0.326\n",
      "Ep 1 (Step 000085): Train loss 0.305, Val loss 0.328\n",
      "Ep 1 (Step 000090): Train loss 0.281, Val loss 0.313\n",
      "Ep 1 (Step 000095): Train loss 0.325, Val loss 0.316\n",
      "Ep 1 (Step 000100): Train loss 0.327, Val loss 0.314\n",
      "Ep 1 (Step 000105): Train loss 0.274, Val loss 0.311\n",
      "Ep 1 (Step 000110): Train loss 0.325, Val loss 0.307\n",
      "Ep 1 (Step 000115): Train loss 0.299, Val loss 0.303\n",
      "Ep 1 (Step 000120): Train loss 0.283, Val loss 0.303\n",
      "Ep 1 (Step 000125): Train loss 0.252, Val loss 0.303\n",
      "Ep 1 (Step 000130): Train loss 0.309, Val loss 0.307\n",
      "Ep 1 (Step 000135): Train loss 0.248, Val loss 0.302\n",
      "Ep 1 (Step 000140): Train loss 0.275, Val loss 0.297\n",
      "Voici une instruction qui décrit une tâche. Rédige une réponse qui complète correctement la demande.  ### Instruction: Convertis 473 ml en L.  ### Response: 473 ml = 0.473 L<|endoftext|>The following is a list of items that make good gifts for Lola, who likes Rock, Paper, Scissors, and Clothes.  Best Gifts for Lola:\n",
      "Ep 2 (Step 000145): Train loss 0.271, Val loss 0.290\n",
      "Ep 2 (Step 000150): Train loss 0.257, Val loss 0.290\n",
      "Ep 2 (Step 000155): Train loss 0.264, Val loss 0.288\n",
      "Ep 2 (Step 000160): Train loss 0.254, Val loss 0.286\n",
      "Ep 2 (Step 000165): Train loss 0.258, Val loss 0.288\n",
      "Ep 2 (Step 000170): Train loss 0.267, Val loss 0.289\n",
      "Ep 2 (Step 000175): Train loss 0.265, Val loss 0.293\n",
      "Ep 2 (Step 000180): Train loss 0.230, Val loss 0.294\n",
      "Ep 2 (Step 000185): Train loss 0.244, Val loss 0.288\n",
      "Ep 2 (Step 000190): Train loss 0.233, Val loss 0.294\n",
      "Ep 2 (Step 000195): Train loss 0.242, Val loss 0.297\n",
      "Ep 2 (Step 000200): Train loss 0.219, Val loss 0.293\n",
      "Ep 2 (Step 000205): Train loss 0.203, Val loss 0.290\n",
      "Ep 2 (Step 000210): Train loss 0.228, Val loss 0.288\n",
      "Ep 2 (Step 000215): Train loss 0.238, Val loss 0.282\n",
      "Ep 2 (Step 000220): Train loss 0.228, Val loss 0.275\n",
      "Ep 2 (Step 000225): Train loss 0.266, Val loss 0.272\n",
      "Ep 2 (Step 000230): Train loss 0.223, Val loss 0.271\n",
      "Ep 2 (Step 000235): Train loss 0.222, Val loss 0.274\n",
      "Ep 2 (Step 000240): Train loss 0.223, Val loss 0.282\n",
      "Ep 2 (Step 000245): Train loss 0.207, Val loss 0.280\n",
      "Ep 2 (Step 000250): Train loss 0.234, Val loss 0.276\n",
      "Ep 2 (Step 000255): Train loss 0.214, Val loss 0.276\n",
      "Ep 2 (Step 000260): Train loss 0.214, Val loss 0.278\n",
      "Ep 2 (Step 000265): Train loss 0.219, Val loss 0.276\n",
      "Ep 2 (Step 000270): Train loss 0.222, Val loss 0.281\n",
      "Ep 2 (Step 000275): Train loss 0.208, Val loss 0.276\n",
      "Ep 2 (Step 000280): Train loss 0.224, Val loss 0.275\n",
      "Ep 2 (Step 000285): Train loss 0.201, Val loss 0.276\n",
      "Voici une instruction qui décrit une tâche. Rédige une réponse qui complète correctement la demande.  ### Instruction: Convertis 473 ml en L.  ### Response: 473 ml = 0.473 L<|endoftext|>The following is a list of items that make good gifts for Kitten, who likes to eat.  Best Gifts for Kitten: pizza, crème, sauce,\n",
      "Training completed in 20.33 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0288b7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from previous_labs import plot_losses\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006b3b2a",
   "metadata": {},
   "source": [
    "## 3° Extracting and saving responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8374f1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voici une instruction qui décrit une tâche. Rédige une réponse qui complète correctement la demande.\n",
      "\n",
      "### Instruction:\n",
      "Convertis 6.81 kg en g.\n",
      "\n",
      "Correct response:\n",
      ">> 6.81 kg = 6810 g\n",
      "\n",
      "Model response:\n",
      ">> 6.81 kg = 681 g\n",
      "-------------------------------------\n",
      "Voici une instruction qui décrit une tâche. Rédige une réponse qui complète correctement la demande.\n",
      "\n",
      "### Instruction:\n",
      "Convertis 9289 g en kg.\n",
      "\n",
      "Correct response:\n",
      ">> 9289 g = 9.289 kg\n",
      "\n",
      "Model response:\n",
      ">> 9289 g = 9.289 kg\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "from previous_labs import *\n",
    "\n",
    "\n",
    "for entry in test_data[60:62]:\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5457b3",
   "metadata": {},
   "source": [
    "On save , les réponses données par le LLM dans un dataset, nommé dataset-with-response et on va évaluer ce dataset à partir d'une IA.\n",
    "\n",
    "On save que les reponses de la partie test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "36df28a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [02:24<00:00,  1.05s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    "\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "\n",
    "with open(\"datasets/instruction-data-with-response.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(test_data, file, ensure_ascii=False, indent=4)  # \"indent\" for pretty-printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e61c61ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as LLM_assistant_cuisine-sft.pth\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "file_name = f\"{re.sub(r'[ ()]', '', \"LLM_assistant_cuisine\") }-sft.pth\"\n",
    "torch.save(model.state_dict(), file_name)\n",
    "print(f\"Model saved as {file_name}\")\n",
    "\n",
    "# Load model via\n",
    "# model.load_state_dict(torch.load(\"LLM_assistant_cuisine.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1cc1b2",
   "metadata": {},
   "source": [
    "## 4° Evaluation du finetuned LLM avec OLLAMA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94caf5cf",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/chapter-overview-7.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f6a324",
   "metadata": {},
   "source": [
    "- In this section, we automate the response evaluation of the finetuned LLM using another, larger LLM\n",
    "- In particular, we use an instruction-finetuned 8 billion parameter Llama 3 model by Meta AI that can be run locally via ollama ([https://ollama.com](https://ollama.com))\n",
    "- (Alternatively, if you prefer using a more capable LLM like GPT-4 via the OpenAI API, please see the [llm-instruction-eval-openai.ipynb](../03_model-evaluation/llm-instruction-eval-openai.ipynb) notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b5fbd9",
   "metadata": {},
   "source": [
    "- Ollama is an application to run LLMs efficiently\n",
    "- It is a wrapper around llama.cpp ([https://github.com/ggerganov/llama.cpp](https://github.com/ggerganov/llama.cpp)), which implements LLMs in pure C/C++ to maximize efficiency\n",
    "- Note that it is a tool for using LLMs to generate text (inference), not training or finetuning LLMs\n",
    "- Before running the code below, install ollama by visiting [https://ollama.com](https://ollama.com) and following the instructions (for instance, clicking on the \"Download\" button and downloading the ollama application for your operating system)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7dac0d",
   "metadata": {},
   "source": [
    "- For macOS and Windows users, click on the ollama application you downloaded; if it prompts you to install the command line usage, say \"yes\"\n",
    "- Linux users can use the installation command provided on the ollama website\n",
    "\n",
    "- In general, before we can use ollama from the command line, we have to either start the ollama application or run `ollama serve` in a separate terminal\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/ollama-run.webp\" width=700px>\n",
    "\n",
    "\n",
    "- With the ollama application or `ollama serve` running in a different terminal, on the command line, execute the following command to try out the 8 billion parameters Llama 3 model (the model, which takes up 4.7 GB of storage space, will be automatically downloaded the first time you execute this command)\n",
    "\n",
    "```bash\n",
    "# 8B model\n",
    "ollama run llama3\n",
    "```\n",
    "\n",
    "\n",
    "The output looks like as follows\n",
    "\n",
    "```\n",
    "$ ollama run llama3\n",
    "pulling manifest\n",
    "pulling 6a0746a1ec1a... 100% ▕████████████████▏ 4.7 GB\n",
    "pulling 4fa551d4f938... 100% ▕████████████████▏  12 KB\n",
    "pulling 8ab4849b038c... 100% ▕████████████████▏  254 B\n",
    "pulling 577073ffcc6c... 100% ▕████████████████▏  110 B\n",
    "pulling 3f8eb4da87fa... 100% ▕████████████████▏  485 B\n",
    "verifying sha256 digest\n",
    "writing manifest\n",
    "removing any unused layers\n",
    "success\n",
    "```\n",
    "\n",
    "- Note that `llama3` refers to the instruction finetuned 8 billion Llama 3 model\n",
    "\n",
    "- Using ollama with the `\"llama3\"` model (a 8B parameter model) requires 16 GB of RAM; if this is not supported by your machine, you can try the smaller model, such as the 3.8B parameter phi-3 model by setting `model = \"phi-3\"`, which only requires 8 GB of RAM\n",
    "\n",
    "- Alternatively, you can also use the larger 70 billion parameters Llama 3 model, if your machine supports it, by replacing `llama3` with `llama3:70b`\n",
    "\n",
    "- After the download has been completed, you will see a command line prompt that allows you to chat with the model\n",
    "\n",
    "- Try a prompt like \"What do llamas eat?\", which should return an output similar to the following\n",
    "\n",
    "```\n",
    ">>> What do llamas eat?\n",
    "Llamas are ruminant animals, which means they have a four-chambered\n",
    "stomach and eat plants that are high in fiber. In the wild, llamas\n",
    "typically feed on:\n",
    "1. Grasses: They love to graze on various types of grasses, including tall\n",
    "grasses, wheat, oats, and barley.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d9439b",
   "metadata": {},
   "source": [
    "- You can end this session using the input `/bye`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d64ab27",
   "metadata": {},
   "source": [
    "- The following code checks whether the ollama session is running correctly before proceeding to use ollama to evaluate the test set responses we generated in the previous section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b230de13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama running: True\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "def check_if_running(process_name):\n",
    "    running = False\n",
    "    for proc in psutil.process_iter([\"name\"]):\n",
    "        if process_name in proc.info[\"name\"]:\n",
    "            running = True\n",
    "            break\n",
    "    return running\n",
    "\n",
    "ollama_running = check_if_running(\"ollama\")\n",
    "\n",
    "if not ollama_running:\n",
    "    raise RuntimeError(\"Ollama not running. Launch ollama before proceeding.\")\n",
    "print(\"Ollama running:\", check_if_running(\"ollama\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1366084a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel = \"llama3\"\\nresult = query_model(\"What do Llamas eat?\", model)\\nprint(result)\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "def query_model(prompt, model=\"llama3\", url=\"http://localhost:11434/api/chat\"):\n",
    "    # Create the data payload as a dictionary\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"options\": {     # Settings below are required for deterministic responses\n",
    "            \"seed\": 123,\n",
    "            \"temperature\": 0,\n",
    "            \"num_ctx\": 2048\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "    # Convert the dictionary to a JSON formatted string and encode it to bytes\n",
    "    payload = json.dumps(data).encode(\"utf-8\")\n",
    "\n",
    "    # Create a request object, setting the method to POST and adding necessary headers\n",
    "    request = urllib.request.Request(url, data=payload, method=\"POST\")\n",
    "    request.add_header(\"Content-Type\", \"application/json\")\n",
    "\n",
    "    # Send the request and capture the response\n",
    "    response_data = \"\"\n",
    "    with urllib.request.urlopen(request) as response:\n",
    "        # Read and decode the response\n",
    "        while True:\n",
    "            line = response.readline().decode(\"utf-8\")\n",
    "            if not line:\n",
    "                break\n",
    "            response_json = json.loads(line)\n",
    "            response_data += response_json[\"message\"][\"content\"]\n",
    "\n",
    "    return response_data\n",
    "\n",
    "\"\"\"\n",
    "model = \"llama3\"\n",
    "result = query_model(\"What do Llamas eat?\", model)\n",
    "print(result)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384b3229",
   "metadata": {},
   "source": [
    "- Now, using the `query_model` function we defined above, we can evaluate the responses of our finetuned model; let's try it out on the first 3 test set responses we looked at in a previous section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8a3335c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voici une instruction qui décrit une tâche. Rédige une réponse qui complète correctement la demande.\n",
      "\n",
      "### Instruction:\n",
      "Convertis 159 ml en cl.\n",
      "\n",
      "Dataset response:\n",
      ">> 159 ml = 15.9 cl\n",
      "\n",
      "Model response:\n",
      ">> 159 ml = 15.9 cl\n",
      "\n",
      "Score:\n",
      ">> I'd rate my own response as 100!\n",
      "\n",
      "The input instruction asks me to convert 159 milliliters (ml) into centiliters (cl). My response, \"159 ml = 15.9 cl\", accurately completes this task by performing the conversion.\n",
      "\n",
      "So, I give myself a perfect score of 100!\n",
      "\n",
      "-------------------------\n",
      "Voici une instruction qui décrit une tâche. Rédige une réponse qui complète correctement la demande.\n",
      "\n",
      "### Instruction:\n",
      "À quelle température cuire un flan.\n",
      "\n",
      "Dataset response:\n",
      ">> Cuisson: four, Température: 180°C, Temps: 40-45 min\n",
      "\n",
      "Model response:\n",
      ">> Cuisson: four, Température: 180°C, Temps: 25-30 min\n",
      "\n",
      "Score:\n",
      ">> I would score this model response as 80 out of 100.\n",
      "\n",
      "The model correctly identified the cooking method (\"four\" or oven) and temperature (180°C), which are the most important details in this instruction. However, it made an error in the cooking time, suggesting 25-30 minutes instead of the correct range of 40-45 minutes.\n",
      "\n",
      "Overall, the model demonstrated a good understanding of the instruction, but a small mistake in one of the details prevented it from achieving a perfect score.\n",
      "\n",
      "-------------------------\n",
      "Voici une instruction qui décrit une tâche. Rédige une réponse qui complète correctement la demande.\n",
      "\n",
      "### Instruction:\n",
      "Convertis 157 ml en cl.\n",
      "\n",
      "Dataset response:\n",
      ">> 157 ml = 15.7 cl\n",
      "\n",
      "Model response:\n",
      ">> 157 ml = 15.7 cl\n",
      "\n",
      "Score:\n",
      ">> I'd rate my own response as 100!\n",
      "\n",
      "The input instruction asks me to convert 157 milliliters (ml) into centiliters (cl). My response, \"157 ml = 15.7 cl\", accurately completes this task by performing the conversion.\n",
      "\n",
      "So, I give myself a perfect score of 100!\n",
      "\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "for entry in test_data[4:7]:\n",
    "    prompt = (\n",
    "        f\"Given the input `{format_input(entry)}` \"\n",
    "        f\"and correct output `{entry['output']}`, \"\n",
    "        f\"score the model response `{entry['model_response']}`\"\n",
    "        f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "    )\n",
    "    print(format_input(entry))\n",
    "    print(\"\\nDataset response:\")\n",
    "    print(\">>\", entry['output'])\n",
    "    print(\"\\nModel response:\")\n",
    "    print(\">>\", entry[\"model_response\"])\n",
    "    print(\"\\nScore:\")\n",
    "    print(\">>\", query_model(prompt))\n",
    "    print(\"\\n-------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a8555802",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries: 100%|██████████| 137/137 [34:23<00:00, 15.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scores: 137 of 137\n",
      "Average score: 74.31\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_model_scores(json_data, json_key, model=\"llama3\"):\n",
    "    scores = []\n",
    "    for entry in tqdm(json_data, desc=\"Scoring entries\"):\n",
    "        prompt = (\n",
    "            f\"Given the input `{format_input(entry)}` \"\n",
    "            f\"and correct output `{entry['output']}`, \"\n",
    "            f\"score the model response `{entry[json_key]}`\"\n",
    "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "            f\"Respond with the integer number only.\"\n",
    "        )\n",
    "        score = query_model(prompt, model)\n",
    "        try:\n",
    "            scores.append(int(score))\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert score: {score}\")\n",
    "            continue\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "scores = generate_model_scores(test_data, \"model_response\")\n",
    "print(f\"Number of scores: {len(scores)} of {len(test_data)}\")\n",
    "print(f\"Average score: {sum(scores)/len(scores):.2f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
